{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a18d50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a03c1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos cargados: 692500 filas de entrenamiento.\n",
      "‚úÖ Valores nulos imputados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# 1. CARGA DE DATOS Y LIMPIEZA INICIAL\n",
    "\n",
    "# Cargamos los datos \n",
    "try:\n",
    "    train = pd.read_csv(\"train.csv\")\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "    print(f\"‚úÖ Datos cargados: {train.shape[0]} filas de entrenamiento.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: No se encuentran 'train.csv' o 'test.csv'. Verifica la ruta.\")\n",
    "    raise\n",
    "\n",
    "# Imputaci√≥n de Valores Nulos (Fundamental antes de crear features)\n",
    "# Num√©ricos -> Mediana | Categ√≥ricos -> Moda\n",
    "def imputar_nulos(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().any():\n",
    "            if df[col].dtype == 'object':\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "            else:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "train = imputar_nulos(train)\n",
    "test_df = imputar_nulos(test_df)\n",
    "print(\"‚úÖ Valores nulos imputados correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ccacca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ingenier√≠a de caracter√≠sticas aplicada (Promedio, Std, Rango).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. FEATURE ENGINEERING agregando Std y Rangos\n",
    "\n",
    "\n",
    "cols_indicadores = [col for col in train.columns if 'INDICADOR_' in col]\n",
    "\n",
    "def crear_features_inteligentes(df):\n",
    "    # Promedio (Se√±al base)\n",
    "    df['INDICADOR_PROMEDIO'] = df[cols_indicadores].mean(axis=1)\n",
    "    \n",
    "    # Desviaci√≥n Est√°ndar (Detecta estudiantes inestables vs constantes)\n",
    "    df['INDICADOR_STD'] = df[cols_indicadores].std(axis=1)\n",
    "    \n",
    "    # Min y Max (Techo y suelo de rendimiento)\n",
    "    df['INDICADOR_MIN'] = df[cols_indicadores].min(axis=1)\n",
    "    df['INDICADOR_MAX'] = df[cols_indicadores].max(axis=1)\n",
    "    \n",
    "    # Rango (Amplitud de habilidades)\n",
    "    df['INDICADOR_RANGO'] = df['INDICADOR_MAX'] - df['INDICADOR_MIN']\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = crear_features_inteligentes(train)\n",
    "test_df = crear_features_inteligentes(test_df)\n",
    "print(\"‚úÖ Ingenier√≠a de caracter√≠sticas aplicada (Promedio, Std, Rango).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08a2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dimensiones finales alineadas -> Train: (692500, 1043), Test: (296786, 1043)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. PREPROCESAMIENTO \n",
    "# Guardamos IDs para el final\n",
    "train_ids = train['ID']\n",
    "test_ids = test_df['ID']\n",
    "target_col = 'RENDIMIENTO_GLOBAL'\n",
    "\n",
    "# Codificar Variable Objetivo (y)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(train[target_col])\n",
    "\n",
    "# Separar variables predictoras\n",
    "X = train.drop(['ID', target_col], axis=1)\n",
    "X_test_real = test_df.drop(['ID'], axis=1)\n",
    "\n",
    "# Concatenar para One-Hot Encoding (Garantiza mismas columnas siempre)\n",
    "X_combined = pd.concat([X, X_test_real], keys=['train', 'test'])\n",
    "X_combined = pd.get_dummies(X_combined, drop_first=True)\n",
    "\n",
    "# Limpieza de nombres de columnas para XGBoost (Elimina caracteres especiales)\n",
    "X_combined.columns = [re.sub(r'[<>()\\[\\]{},.:;\\'\\\"-/]', '_', col) for col in X_combined.columns]\n",
    "\n",
    "# Separar nuevamente\n",
    "X_train_final = X_combined.loc['train'].reset_index(drop=True)\n",
    "X_test_final = X_combined.loc['test'].reset_index(drop=True)\n",
    "\n",
    "print(f\"‚úÖ Dimensiones finales alineadas -> Train: {X_train_final.shape}, Test: {X_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Entrenando modelo XGBoost Super-Tuned (esto puede tardar unos minutos)...\n",
      "[0]\tvalidation_0-mlogloss:1.38376\tvalidation_1-mlogloss:1.38381\n",
      "[200]\tvalidation_0-mlogloss:1.25651\tvalidation_1-mlogloss:1.26131\n",
      "[400]\tvalidation_0-mlogloss:1.23329\tvalidation_1-mlogloss:1.24134\n",
      "[600]\tvalidation_0-mlogloss:1.22014\tvalidation_1-mlogloss:1.23095\n",
      "[800]\tvalidation_0-mlogloss:1.21092\tvalidation_1-mlogloss:1.22431\n",
      "[1000]\tvalidation_0-mlogloss:1.20382\tvalidation_1-mlogloss:1.21953\n",
      "[1200]\tvalidation_0-mlogloss:1.19802\tvalidation_1-mlogloss:1.21596\n",
      "[1400]\tvalidation_0-mlogloss:1.19301\tvalidation_1-mlogloss:1.21309\n",
      "[1600]\tvalidation_0-mlogloss:1.18870\tvalidation_1-mlogloss:1.21079\n",
      "[1800]\tvalidation_0-mlogloss:1.18474\tvalidation_1-mlogloss:1.20883\n",
      "[2000]\tvalidation_0-mlogloss:1.18118\tvalidation_1-mlogloss:1.20714\n",
      "[2200]\tvalidation_0-mlogloss:1.17798\tvalidation_1-mlogloss:1.20575\n",
      "[2400]\tvalidation_0-mlogloss:1.17493\tvalidation_1-mlogloss:1.20449\n",
      "[2600]\tvalidation_0-mlogloss:1.17209\tvalidation_1-mlogloss:1.20337\n",
      "[2800]\tvalidation_0-mlogloss:1.16940\tvalidation_1-mlogloss:1.20240\n",
      "[2999]\tvalidation_0-mlogloss:1.16686\tvalidation_1-mlogloss:1.20151\n",
      "üéâ ¬°Modelo entrenado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. CONFIGURACI√ìN Y ENTRENAMIENTO \n",
    "\n",
    "X_t, X_val, y_t, y_val = train_test_split(\n",
    "    X_train_final, \n",
    "    y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Par√°metros optimizados\n",
    "xgb_params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(le.classes_),\n",
    "    'n_estimators': 3000,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.75,\n",
    "    'colsample_bytree': 0.65,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0.1,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "print(\"‚öôÔ∏è Entrenando modelo XGBoost Super-Tuned...\")\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(**xgb_params)\n",
    "\n",
    "\n",
    "# CONVERTIMOS EXPLICITAMENTE LAS MATRICES X A ARRAYS DE NUMPY USANDO .values\n",
    "model_xgb.fit(\n",
    "    X_t.values, \n",
    "    y_t,\n",
    "    eval_set=[(X_t.values, y_t), (X_val.values, y_val)],\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "print(\"üéâ ¬°Modelo entrenado exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac3e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Generando predicciones...\n",
      "‚úÖ Archivo generado: submission_xgb_features_avanzadas_v2.csv\n",
      "Muestra de las primeras 5 filas:\n",
      "       ID RENDIMIENTO_GLOBAL\n",
      "0  550236               bajo\n",
      "1   98545         medio-alto\n",
      "2  499179               alto\n",
      "3  782980               bajo\n",
      "4  785185               bajo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. GENERACI√ìN DE RESULTADOS Y ARCHIVO DE ENV√çO\n",
    "\n",
    "print(\"üìù Generando predicciones...\")\n",
    "\n",
    "# Predecir\n",
    "\n",
    "preds_numeric = model_xgb.predict(X_test_final.values) \n",
    "# Decodificar \n",
    "preds_text = le.inverse_transform(preds_numeric)\n",
    "\n",
    "# Crear DataFrame final\n",
    "submission_pro = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'RENDIMIENTO_GLOBAL': preds_text\n",
    "})\n",
    "\n",
    "# Guardar\n",
    "nombre_archivo = 'submission_xgb_features_avanzadas_v2.csv'\n",
    "submission_pro.to_csv(nombre_archivo, index=False)\n",
    "\n",
    "print(f\"‚úÖ Archivo generado: {nombre_archivo}\")\n",
    "print(\"Muestra de las primeras 5 filas:\")\n",
    "print(submission_pro.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fad328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IMPORTS ADICIONALES ---\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression # Nuestro meta-modelo\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Iniciando entrenamiento con Stacking Ensemble (5 pliegues)...\n",
      "\n",
      "--- Pliegue 1/5 ---\n",
      "\n",
      "--- Pliegue 2/5 ---\n",
      "\n",
      "--- Pliegue 3/5 ---\n",
      "\n",
      "--- Pliegue 4/5 ---\n",
      "\n",
      "--- Pliegue 5/5 ---\n",
      "‚úÖ Entrenamiento de Modelos Base completado.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. ENTRENAMIENTO DE MODELOS BASE CON STACKING (LightGBM y XGBoost)\n",
    "\n",
    "\n",
    "NFOLDS = 5 # N√∫mero de pliegues (splits)\n",
    "SEED = 42\n",
    "skf = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Inicializar arrays para almacenar predicciones fuera de pliegue (OOF)\n",
    "oof_preds_xgb = np.zeros((X_train_final.shape[0], len(le.classes_)))\n",
    "oof_preds_lgbm = np.zeros((X_train_final.shape[0], len(le.classes_)))\n",
    "\n",
    "# Inicializar arrays para almacenar predicciones de prueba promediadas\n",
    "test_preds_xgb = np.zeros((X_test_final.shape[0], len(le.classes_)))\n",
    "test_preds_lgbm = np.zeros((X_test_final.shape[0], len(le.classes_)))\n",
    "\n",
    "# --- Par√°metros de XGBoost ---\n",
    "xgb_params = {\n",
    "    'objective': 'multi:softprob', \n",
    "    'num_class': len(le.classes_),\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.75,\n",
    "    'colsample_bytree': 0.65,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'n_jobs': -1,\n",
    "    'random_state': SEED,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "# --- Par√°metros de LightGBM \n",
    "lgbm_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(le.classes_),\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 35,\n",
    "    'reg_lambda': 0.1,\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# ----------------- INICIO DEL K-FOLD -----------------\n",
    "print(f\"‚öôÔ∏è Iniciando entrenamiento con Stacking Ensemble ({NFOLDS} pliegues)...\")\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(X_train_final, y_encoded)):\n",
    "    print(f\"\\n--- Pliegue {fold+1}/{NFOLDS} ---\")\n",
    "    \n",
    "    # Preparaci√≥n de datos para el pliegue\n",
    "    X_train, X_val = X_train_final.iloc[train_index], X_train_final.iloc[val_index]\n",
    "    y_train, y_val = y_encoded[train_index], y_encoded[val_index]\n",
    "    \n",
    "    # 1. Modelo XGBoost Base\n",
    "    model_xgb = xgb.XGBClassifier(**xgb_params)\n",
    "    model_xgb.fit(\n",
    "        X_train.values, y_train,\n",
    "        eval_set=[(X_val.values, y_val)],\n",
    "        verbose=False,\n",
    "    )\n",
    "    # Almacenar predicciones fuera de pliegue (OOF) y de prueba\n",
    "    oof_preds_xgb[val_index] = model_xgb.predict_proba(X_val.values)\n",
    "    test_preds_xgb += model_xgb.predict_proba(X_test_final.values) / NFOLDS\n",
    "\n",
    "    # 2. Modelo LightGBM \n",
    "    model_lgbm = lgb.LGBMClassifier(**lgbm_params)\n",
    "    model_lgbm.fit(\n",
    "        X_train.values, y_train,\n",
    "        eval_set=[(X_val.values, y_val)],\n",
    "        eval_metric='multi_logloss',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    "    )\n",
    "    # Almacenar predicciones fuera de pliegue (OOF) y de prueba\n",
    "    oof_preds_lgbm[val_index] = model_lgbm.predict_proba(X_val.values)\n",
    "    test_preds_lgbm += model_lgbm.predict_proba(X_test_final.values) / NFOLDS\n",
    "\n",
    "print(\"‚úÖ Entrenamiento de Modelos Base completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4788627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Entrenando Meta-Modelo (Logistic Regression)...\n",
      "‚úÖ Meta-Modelo entrenado.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. ENTRENAMIENTO DEL META-MODELO (STACKING)\n",
    "\n",
    "\n",
    "# Crear el conjunto de datos de Nivel 2 (Meta-Features)\n",
    "# Las nuevas features son las probabilidades de cada clase (4 clases) de cada modelo (2 modelos)\n",
    "X_meta = np.hstack((oof_preds_xgb, oof_preds_lgbm))\n",
    "\n",
    "# Crear el conjunto de datos de prueba de Nivel 2\n",
    "X_meta_test = np.hstack((test_preds_xgb, test_preds_lgbm))\n",
    "\n",
    "# Meta-Modelo: Regresi√≥n Log√≠stica \n",
    "print(\"‚öôÔ∏è Entrenando Meta-Modelo (Logistic Regression)...\")\n",
    "meta_model = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    multi_class='multinomial',\n",
    "    C=0.1, \n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenar el Meta-Modelo\n",
    "meta_model.fit(X_meta, y_encoded)\n",
    "print(\"‚úÖ Meta-Modelo entrenado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b52e2681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "√âXITO: Stacking Ensemble completado. Archivo generado: submission_STACKING_FINAL.csv\n",
      "       ID RENDIMIENTO_GLOBAL\n",
      "0  550236               bajo\n",
      "1   98545         medio-alto\n",
      "2  499179               alto\n",
      "3  782980               bajo\n",
      "4  785185               bajo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. PREDICCI√ìN FINAL Y SUBMISI√ìN\n",
    "\n",
    "\n",
    "# Predicci√≥n final del Meta-Modelo\n",
    "final_probas = meta_model.predict_proba(X_meta_test)\n",
    "\n",
    "# Obtener la clase con la probabilidad m√°s alta\n",
    "final_predictions_numeric = np.argmax(final_probas, axis=1)\n",
    "\n",
    "# Decodificar\n",
    "final_predictions_text = le.inverse_transform(final_predictions_numeric)\n",
    "\n",
    "# Crear y guardar el archivo de env√≠o\n",
    "submission_ensemble_df = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'RENDIMIENTO_GLOBAL': final_predictions_text\n",
    "})\n",
    "\n",
    "nombre_archivo_final = 'submission_STACKING_FINAL.csv'\n",
    "submission_ensemble_df.to_csv(nombre_archivo_final, index=False)\n",
    "\n",
    "print(f\"\\n=========================================================\")\n",
    "print(f\"√âXITO: Stacking Ensemble completado. Archivo generado: {nombre_archivo_final}\")\n",
    "print(submission_ensemble_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
